{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets for Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## [ABCEats Restaurant Data](https://a816-health.nyc.gov/ABCEatsRestaurants/#/Search) \n",
    "\n",
    "Downloaded dataset from [NYC Open Data](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File datasets/DOHMH_New_York_City_Restaurant_Inspection_Results.csv does not exist: 'datasets/DOHMH_New_York_City_Restaurant_Inspection_Results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aaf07956082f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/DOHMH_New_York_City_Restaurant_Inspection_Results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File datasets/DOHMH_New_York_City_Restaurant_Inspection_Results.csv does not exist: 'datasets/DOHMH_New_York_City_Restaurant_Inspection_Results.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/DOHMH_New_York_City_Restaurant_Inspection_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['CUISINE DESCRIPTION']\n",
    "lst = df['CUISINE DESCRIPTION'].value_counts()\n",
    "lst[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese_2020\n",
    "\n",
    "'Chinese', 'Chinese/Japanese', 'Chinese/Cuban'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chinese_2020 = df['CUISINE DESCRIPTION'] == ('Chinese' or 'Chinese/Japanese' or 'Chinese/Cuban')\n",
    "CH2020 = df.loc[Chinese_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "CH2020.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH2020.to_csv(r'Chinese_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "French_2020 = df['CUISINE DESCRIPTION'] == 'French'\n",
    "FR2020 = df.loc[French_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "FR2020.to_csv(r'French_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Russian_2020 = df['CUISINE DESCRIPTION'] == 'Russian'\n",
    "RS2020 = df.loc[Russian_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "RS2020.to_csv(r'Russian_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Italian_2020 = df['CUISINE DESCRIPTION'] == 'Italian'\n",
    "IT2020 = df.loc[Italian_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "IT2020.to_csv(r'Italian_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish_2020\n",
    "\n",
    "'Spanish', 'Tapas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spanish_2020 = df['CUISINE DESCRIPTION'] == ('Spanish' or 'Tapas')\n",
    "SP2020 = df.loc[Spanish_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "SP2020.to_csv(r'Spanish_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jewish_2020\n",
    "\n",
    "'Jewish/Kosher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jewish_2020 = (df['CUISINE DESCRIPTION'] == 'Jewish/Kosher') \n",
    "JW2020 = df.loc[Jewish_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "JW2020.to_csv(r'Jewish_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German_2020\n",
    "\n",
    "'Delicatessen', 'German'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German_2020 = df['CUISINE DESCRIPTION'] == ('Delicatessen' or 'German') \n",
    "GM2020 = df.loc[German_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "GM2020.to_csv(r'German_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irish_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Irish_2020 = df['CUISINE DESCRIPTION'] == 'Irish'\n",
    "IR2020 = df.loc[Irish_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "IR2020.to_csv(r'Irish_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polish_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Polish_2020 = df['CUISINE DESCRIPTION'] == 'Polish'\n",
    "PL2020 = df.loc[Polish_2020, ['DBA','BORO', 'BUILDING', 'STREET', 'ZIPCODE', 'Latitude', 'Longitude']]\n",
    "PL2020.to_csv(r'Polish_2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other category of food that didn't exist at the time \n",
    "\n",
    "### Culture food\n",
    "- 'American'\n",
    "- 'Indian'\n",
    "- 'Thai'\n",
    "- 'Mediterranean'\n",
    "- 'Middle Eastern'\n",
    "- 'Greek'\n",
    "- 'Vietnamese/Cambodian/Malaysia'\n",
    "- 'African'\n",
    "- 'Turkish'\n",
    "- 'Bangladeshi'\n",
    "- 'Filipino'\n",
    "- 'Pakistani'\n",
    "- 'Hawaiian'\n",
    "- 'Continental'\n",
    "- 'Brazilian'\n",
    "- 'Australian'\n",
    "\n",
    "### Category food\n",
    "- 'Caf√©/Coffee/Tea'\n",
    "- **'Pizza'** -- Italian?\n",
    "- 'Bakery'\n",
    "- 'Donuts'\n",
    "- 'Juice, Smoothies, Fruit Salads'\n",
    "- 'Hamburgers'\n",
    "- 'Sandwiches'\n",
    "- 'Seafood'\n",
    "- 'Ice Cream, Gelato, Yogurt, Ices'\n",
    "- 'Sandwiches/Salads/Mixed Buffet'\n",
    "- **'Bagels/Pretzels'** -- Bagels are Jewish and Pretzels and German?\n",
    "- 'Vegetarian'\n",
    "- 'Steak'\n",
    "- 'Bottled beverages, including water, sodas, juices, etc.'\n",
    "- 'Soul Food'\n",
    "- 'Salads'\n",
    "- 'Barbecue'\n",
    "- 'Soups & Sandwiches'\n",
    "- 'Creole'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2019 Abdala Nationality_Gender_1898TrowBus \"March 26 Plotting\" sheet](https://docs.google.com/spreadsheets/d/1D154NR_0JElKssEAw4Y2RmUzwkSxR533DrDC46pU2uU/edit#gid=572697680)\n",
    "\n",
    "Google Sheet from shared drive downloaded as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('datasets/2019 Abdala Nationality_Gender_1898TrowBus - March 26 Plotting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst2 = df2['Nationality Final'].value_counts()\n",
    "lst2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German_1898\n",
    "\n",
    "'German', 'German/Austrian', 'Austrian/German', 'German, Austrian, Czech?', 'Gernan', 'German, Prussian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German_1898 = df2['Nationality Final'] == ('German' or 'German/Austrian' \n",
    "                                           or 'Austrian/German' or 'German, Austrian, Czech?' \n",
    "                                           or 'Gernan' or 'German, Prussian') \n",
    "GM1898 = df2.loc[German_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "GM1898.to_csv(r'German_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian_1898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Italian_1898 = df2['Nationality Final'] == 'Italian'\n",
    "IT1898 = df2.loc[Italian_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "IT1898.to_csv(r'Italian_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jewish_1898\n",
    "\n",
    "'Jewish', 'Jewish, German', 'Jewish, Russian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jewish_1898 = df2['Nationality Final'] == ('Jewish' or 'Jewish, German' or 'Jewish, Russian') \n",
    "JW1898 = df2.loc[Jewish_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "JW1898.to_csv(r'Jewish_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French_1898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "French_1898 = df2['Nationality Final'] == 'French'\n",
    "FR1898 = df2.loc[French_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "FR1898.to_csv(r'French_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian_1898\n",
    "\n",
    "'Russian', 'Russian/Romanian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Russian_1898 = df2['Nationality Final'] == ('Russian' or 'Russian/Romanian') \n",
    "RS1898 = df2.loc[Russian_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "RS1898.to_csv(r'Russian_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish_1898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spanish_1898 = df2['Nationality Final'] == 'Spanish'\n",
    "SP1898 = df2.loc[Spanish_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "SP1898.to_csv(r'Spanish_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese_1898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chinese_1898 = df2['Nationality Final'] == 'Chinese'\n",
    "CH1898 = df2.loc[Chinese_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "CH1898.to_csv(r'Chinese_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irish_1898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Irish_1898 = df2['Nationality Final'] == 'Irish'\n",
    "IR1898 = df2.loc[Irish_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "IR1898.to_csv(r'Irish_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polish_1898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Polish_1898 = df2['Nationality Final'] == 'Polish'\n",
    "PL1898 = df2.loc[Polish_1898, ['Name', 'Address', 'Nationality Final']]\n",
    "PL1898.to_csv(r'Polish_1898.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2019 Abdala National and Gender 1913 Trow sheet](https://docs.google.com/spreadsheets/d/1-PhdqRmy7AfbV-Je6vziABKruAOivNFRMPrvwGsM7ro/edit#gid=89465283)\n",
    "\n",
    "Google Sheet from shared drive downloaded as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('datasets/1913 - 1913 Trows Bus Dir Man EXCERPT .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst3 = df3['NATIONALITY final'].value_counts()\n",
    "lst3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "German_1913 = df3['NATIONALITY final'] == ('German' or 'german')\n",
    "GM1913 = df3.loc[German_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "GM1913.to_csv(r'German_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Italian_1913 = df3['NATIONALITY final'] == 'Italian'\n",
    "IT1913 = df3.loc[Italian_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "IT1913.to_csv(r'Italian_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jewish_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jewish_1913 = df3['NATIONALITY final'] == 'Jewish'\n",
    "JW1913 = df3.loc[Jewish_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "JW1913.to_csv(r'Jewish_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "French_1913 = df3['NATIONALITY final'] == 'French'\n",
    "FR1913 = df3.loc[French_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "FR1913.to_csv(r'French_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Russian_1913 = df3['NATIONALITY final'] == 'Russian' \n",
    "RS1913 = df3.loc[Russian_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "RS1913.to_csv(r'Russian_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spanish_1913 = df3['NATIONALITY final'] == 'Spanish'\n",
    "SP1913 = df3.loc[Spanish_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "SP1913.to_csv(r'Spanish_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chinese_1913 = df3['NATIONALITY final'] == 'Chinese'\n",
    "CH1913 = df3.loc[Chinese_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "CH1913.to_csv(r'Chinese_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irish_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Irish_1913 = df3['NATIONALITY final'] == 'Irish'\n",
    "IR1913 = df3.loc[Irish_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "IR1913.to_csv(r'Irish_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polish_1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Polish_1913 = df3['NATIONALITY final'] == 'Polish'\n",
    "PL1913 = df3.loc[Polish_1913, ['Name', 'Address', 'NATIONALITY final']]\n",
    "PL1913.to_csv(r'Polish_1913.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit0209044da7c742dab8314e0953beb93b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
